{
  "metadata": {
    "name": "Llama 3.2 Reasoning WebGPU",
    "language_info": {
      "name": "JavaScript",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "// Import the transformers.js library\nconst { AutoTokenizer, AutoModelForCausalLM } = await import('https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.3.3');\n\n// Check for WebGPU support\nconst adapter = await navigator.gpu?.requestAdapter();\nif (!adapter) {\n  throw new Error(\"WebGPU is not supported (no adapter found)\");\n}\nconsole.log(\"WebGPU is supported!\");\n\n// Model ID - MiniThinky reasoning model\nconst model_id = \"ngxson/MiniThinky-v2-1B-Llama-3.2\";\n\n// Load tokenizer and model\nconsole.log(\"Loading model...\");\nconst tokenizer = await AutoTokenizer.from_pretrained(model_id);\nconst model = await AutoModelForCausalLM.from_pretrained(model_id, {\n  dtype: \"q4f16\",\n  device: \"webgpu\"\n});\n\n// Store in window for access across cells\nwindow.tokenizer = tokenizer;\nwindow.model = model;\n\n// Get special token IDs for thinking and answer markers\nconst [THINKING_TOKEN_ID, ANSWER_TOKEN_ID] = window.tokenizer.encode(\n  \"<|thinking|><|answer|>\",\n  { add_special_tokens: false }\n);\nwindow.THINKING_TOKEN_ID = THINKING_TOKEN_ID;\nwindow.ANSWER_TOKEN_ID = ANSWER_TOKEN_ID;\n\nconsole.log(\"Model loaded successfully!\");",
      "status": "[-]",
      "output": "",
      "type": "code"
    },
    {
      "code": "// Define your prompt\nconst messages = [\n  {\n    role: \"system\",\n    content: \"You are MiniThinky, a helpful AI assistant. You always think before giving the answer. Use <|thinking|> before thinking and <|answer|> before giving the answer.\"\n  },\n  { role: \"user\", content: \"What would happen if we doubled the size of the moon?\" }\n];\n\n// Prepare input with chat template\nconst inputs = window.tokenizer.apply_chat_template(messages, {\n  add_generation_prompt: true,\n  return_dict: true\n});\n\n// Track state (thinking or answering)\nlet state = \"thinking\";\nlet thinkingOutput = \"\";\nlet answerOutput = \"\";\n\n// Generate text\nconsole.log(\"Generating response...\");\nconst output = await window.model.generate({\n  ...inputs,\n  do_sample: false,\n  repetition_penalty: 1.1,\n  max_new_tokens: 1024,\n  callback_function: (token) => {\n    // Check if we're transitioning from thinking to answering\n    if (token === \"<|answer|>\") {\n      state = \"answering\";\n      console.log(\"\\n--- Transitioning to answer ---\\n\");\n      return;\n    }\n    \n    // Collect output based on current state\n    if (state === \"thinking\") {\n      thinkingOutput += token;\n    } else {\n      answerOutput += token;\n    }\n    \n    // Log token by token\n    process.stdout.write(token);\n  },\n  token_callback_function: (tokens) => {\n    // Check if the current token is the answer token\n    if (tokens[0] === window.ANSWER_TOKEN_ID) {\n      state = \"answering\";\n    }\n  }\n});\n\n// Store in window for access in next cell\nwindow.thinkingOutput = thinkingOutput;\nwindow.answerOutput = answerOutput;\n\n// Display the raw formatted response\nconsole.log(\"\\n\\nThinking process:\");\nconsole.log(thinkingOutput);\nconsole.log(\"\\nFinal answer:\");\nconsole.log(answerOutput);",
      "status": "[-]",
      "output": "",
      "type": "code"
    },
    {
      "code": "// Create a formatted HTML output for better readability\nconst formattedHTML = `<div style=\"font-family: system-ui; line-height: 1.5; padding: 1rem; max-width: 800px; margin: 0 auto;\">\n  <h3>Thinking Process:</h3>\n  <div style=\"white-space: pre-wrap; background: #f8f8f8; padding: 1rem; border-radius: 8px; border: 1px solid #ddd; color: #666; font-style: italic;\">\n    ${window.thinkingOutput.replace(/\\*\\*(.*?)\\*\\*/g, '<strong>$1</strong>')}\n  </div>\n  \n  <h3>Answer:</h3>\n  <div style=\"white-space: pre-wrap; background: #f5f5f5; padding: 1rem; border-radius: 8px; border: 1px solid #ddd; margin-top: 1rem;\">\n    ${window.answerOutput.replace(/\\*\\*(.*?)\\*\\*/g, '<strong>$1</strong>')}\n  </div>\n</div>`;\n\n// Return the HTML to be displayed in the cell's output\nformattedHTML;",
      "status": "[-]",
      "output": "",
      "type": "code"
    }
  ],
  "source": "https://github.com/EXTREMOPHILARUM/scribbler-notebooks",
  "run_on_load": false
}
