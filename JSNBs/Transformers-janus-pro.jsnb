{
  "metadata": {
    "name": "janus-pro",
    "language_info": {
      "name": "JavaScipt",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "// Dynamically import the ONNX Runtime Web library\nconst ort = await import('https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1');\n\nscrib.show(ort)\nconst session = ort.InferenceSession.create(\n      'https://huggingface.co/onnx-community/Janus-Pro-1B-ONNX/resolve/main/model.onnx',\n      {\n        executionProviders: ['webgpu','wasm'], \n      }\n    );",
      "status": "",
      "output": "<p>// Dynamically import the ONNX Runtime Web library\nconst ort = await import('<a href=\"https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1\">https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1</a>');</p>\n<p>scrib.show(ort)\nconst session = ort.InferenceSession.create(\n      '<a href=\"https://huggingface.co/onnx-community/Janus-Pro-1B-ONNX/resolve/main/model.onnx\">https://huggingface.co/onnx-community/Janus-Pro-1B-ONNX/resolve/main/model.onnx</a>',\n      {\n        executionProviders: ['webgpu','wasm'], \n      }\n    );</p>\n",
      "type": "html"
    },
    {
      "code": "// Dynamically import the Transformers.js library\nconst { AutoProcessor, MultiModalityCausalLM } = await import('https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.3.3');\nconst modelId = 'onnx-community/Janus-Pro-1B-ONNX';\nprocessor = await AutoProcessor.from_pretrained(modelId);\nmodel = await MultiModalityCausalLM.from_pretrained(modelId, {\n\tquantized: true, // Use the quantized model for better performance\n    device: 'webgpu', // Use 'webgpu' for GPU acceleration; fallback to 'wasm' if not supported\n\t});\n",
      "status": "[-]",
      "output": "<p class=\"error\">Aborted(). Build with -sASSERTIONS for more info.</p>",
      "type": "code"
    },
    {
      "code": "    const conversation = [\n      {\n        role: '<|User|>',\n        content: textPrompt,\n      },\n    ];\n\n    // Process the inputs\n    const inputs = await processor(conversation, { chat_template: 'text_to_image' });\n\n    // Generate response\n    const numImageTokens = processor.num_image_tokens;\n    const outputs = await model.generate_images({\n      ...inputs,\n      min_new_tokens: numImageTokens,\n      max_new_tokens: numImageTokens,\n      do_sample: true,\n    });\n\n    // Display the generated image\n    const imageBlob = await outputs[0].toBlob();\n    const imageUrl = URL.createObjectURL(imageBlob);\n    const imgElement = document.createElement('img');\n    imgElement.src = imageUrl;",
      "status": "",
      "output": "",
      "type": "code"
    }
  ],
  "source": "https://github.com/gopi-suvanam/scribbler",
  "run_on_load": false
}